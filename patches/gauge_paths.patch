diff --git a/include/gauge_field_order.h b/include/gauge_field_order.h
index 714ad7d..27f5560 100644
--- a/include/gauge_field_order.h
+++ b/include/gauge_field_order.h
@@ -1535,6 +1535,10 @@ namespace quda {
           }
         }
 
+        FloatNOrder(const GaugeField *u, Float *gauge_ = 0, Float **ghost_ = 0) :
+	  FloatNOrder(*u, gauge_, ghost_)
+	{}
+	
       __device__ __host__ inline void load(complex v[length / 2], int x, int dir, int parity, real phase = 1.0) const
       {
         const int M = reconLen / N;
diff --git a/include/gauge_path_helper.cuh b/include/gauge_path_helper.cuh
index d1c2ae5..e8cc951 100644
--- a/include/gauge_path_helper.cuh
+++ b/include/gauge_path_helper.cuh
@@ -22,19 +22,23 @@ namespace quda {
     paths(std::vector<int**>& input_path, std::vector<int>& length_h, std::vector<double>& path_coeff_h, int num_paths, int max_length) :
       num_paths(num_paths),
       max_length(max_length),
+      path_coeff(nullptr),
       count(0)
     {
       if (static_cast<int>(input_path.size()) != dim)
         errorQuda("Input path vector is of size %lu, expected %d", input_path.size(), dim);
       if (static_cast<int>(length_h.size()) != num_paths)
         errorQuda("Path length vector is of size %lu, expected %d", length_h.size(), num_paths);
-      if (static_cast<int>(path_coeff_h.size()) != num_paths)
-        errorQuda("Path coefficient vector is of size %lu, expected %d", path_coeff_h.size(), num_paths);
 
       // create path struct in a single allocation
       size_t bytes = dim * num_paths * max_length * sizeof(int) + num_paths * sizeof(int);
-      int pad = ((sizeof(double) - bytes % sizeof(double)) % sizeof(double))/sizeof(int);
-      bytes += pad*sizeof(int) + num_paths*sizeof(double);
+      int pad = 0;
+      if (path_coeff_h.size()>0) {
+	if (static_cast<int>(path_coeff_h.size()) != num_paths)
+	  errorQuda("Path coefficient vector is of size %lu, expected %d", path_coeff_h.size(), num_paths);
+	pad = ((sizeof(double) - bytes % sizeof(double)) % sizeof(double))/sizeof(int);
+	bytes += pad*sizeof(int) + num_paths*sizeof(double);
+      }
 
       buffer = static_cast<int*>(pool_device_malloc(bytes));
       int *path_h = static_cast<int*>(safe_malloc(bytes));
@@ -53,8 +57,11 @@ namespace quda {
       // length array
       memcpy(path_h + dim * num_paths * max_length, length_h.data(), num_paths*sizeof(int));
 
-      // path_coeff array
-      memcpy(path_h + dim * num_paths * max_length + num_paths + pad, path_coeff_h.data(), num_paths*sizeof(double));
+      if (path_coeff_h.size()>0) {
+	// path_coeff array
+	memcpy(path_h + dim * num_paths * max_length + num_paths + pad, path_coeff_h.data(), num_paths*sizeof(double));
+	path_coeff = reinterpret_cast<double*>(buffer + dim * num_paths * max_length + num_paths + pad);
+      }
 
       qudaMemcpy(buffer, path_h, bytes, qudaMemcpyHostToDevice);
       host_free(path_h);
@@ -62,7 +69,6 @@ namespace quda {
       // finally set the pointers to the correct offsets in the buffer
       for (int d=0; d < dim; d++) this->input_path[d] = buffer + d*num_paths*max_length;
       length = buffer + dim*num_paths*max_length;
-      path_coeff = reinterpret_cast<double*>(buffer + dim * num_paths * max_length + num_paths + pad);
     }
 
     void free() {
@@ -85,16 +91,21 @@ namespace quda {
      @param[in] dx Temporary shared memory storage for relative coordinate shift
   */
   template <typename Arg, typename I>
-  __device__ __host__ inline typename Arg::Link
+  __device__ __host__ inline typename Arg::Link&
   computeGaugePath(const Arg &arg, int x[4], int parity, const int* path, int length, I& dx)
   {
     using Link = typename Arg::Link;
 
     // linkA: current matrix
     // linkB: the loaded matrix in this round
-    Link linkA, linkB;
-    setIdentity(&linkA);
+    Link linkA;
+
+    if (length==0) {
+      setIdentity(&linkA);
+      return linkA;
+    }
 
+    Link linkB;
     int nbr_oddbit = parity;
 
     for (int j = 0; j < length; j++) {
@@ -104,19 +115,105 @@ namespace quda {
 
       if (isForwards(pathj)) {
         linkB = arg.u(lnkdir, linkIndexShift(x,dx,arg.E), nbr_oddbit);
-        linkA = linkA * linkB;
         dx[lnkdir]++; // now have to update to new location
         nbr_oddbit = nbr_oddbit^1;
       } else {
         dx[lnkdir]--; // if we are going backwards the link is on the adjacent site
         nbr_oddbit = nbr_oddbit^1;
         linkB = arg.u(lnkdir, linkIndexShift(x,dx,arg.E), nbr_oddbit);
-        linkA = linkA * conj(linkB);
+	linkB = conj(linkB);
       }
+      if (j>0)
+	linkA = linkA * linkB;
+      else
+	linkA = linkB;
     } //j
 
     return linkA;
   }
 
+  template <typename Link>
+  struct LinkPair {
+    Link A,B;
+  };
+
+  
+  /**
+     @brief Calculates an arbitary gauge path with insertion, returning the product matrix
+
+     @return The product of the gauge path
+     @param[in] arg Kernel argumnt
+     @param[in] x Full index array
+     @param[in] parity Parity index (note: assumes that an offset from a non-zero dx is baked in)
+     @param[in] path Gauge link path
+     @param[in] length Length of gauge path
+     @param[in] dx Temporary shared memory storage for relative coordinate shift
+  */
+  template <typename Arg, typename I>
+  __device__ __host__ inline LinkPair<typename Arg::Link>&
+  computeGaugePathWIns(const Arg &arg, int x[4], int parity, const int* path, int length, I& dx)
+  {
+    using Link = typename Arg::Link;
+
+    // aux[0]: current matrix
+    // aux[1]: the loaded matrix in this round
+    LinkPair<Link> out;
+    if (length==0) {
+      setIdentity(&out.A);
+      setIdentity(&out.B);
+      return out;
+    }
+    
+    Link aux0, aux1, aux2;
+    int nbr_oddbit = parity;
+
+    for (int j = 0; j < length; j++) {
+
+      int pathj = path[j];
+      int lnkdir = isForwards(pathj) ? pathj : flipDir(pathj);
+
+      if (isForwards(pathj)) {
+	aux0 = arg.u(lnkdir, linkIndexShift(x,dx,arg.E), nbr_oddbit);
+	aux1 = arg.ins(lnkdir, linkIndexShift(x,dx,arg.E), nbr_oddbit);
+	if (not (arg.left and j==0)) {
+	  aux1 = aux1 * aux0;
+	}
+        dx[lnkdir]++; // now have to update to new location
+        nbr_oddbit = nbr_oddbit^1;
+      } else {
+        dx[lnkdir]--; // if we are going backwards the link is on the adjacent site
+        nbr_oddbit = nbr_oddbit^1;
+	aux0 = arg.u(lnkdir, linkIndexShift(x,dx,arg.E), nbr_oddbit);
+	aux0 = conj(aux0);
+	aux1 = arg.ins(lnkdir, linkIndexShift(x,dx,arg.E), nbr_oddbit);
+	if (not (arg.left and j==0)) {
+	  aux1 = - aux0 * aux1;
+	}
+      }
+
+      if (j>0) {
+	if(arg.left and j==1)
+	  out.B = out.A * aux1;
+	else
+	  out.B = out.B * aux0 + out.A * aux1;
+	out.A = out.A * aux0;
+      }
+      else if(arg.left) {
+	out.A = aux0;
+	aux2 = aux1;
+      }
+      else {
+	out.A = aux0;
+	out.B = aux1;
+      }
+    } //j
+
+    if(arg.left) {
+      out.B = out.B + out.A*aux2;
+    }
+    
+    return out;
+  }
+
 }
 
diff --git a/include/gauge_path_quda.h b/include/gauge_path_quda.h
index db398c1..63db338 100644
--- a/include/gauge_path_quda.h
+++ b/include/gauge_path_quda.h
@@ -11,7 +11,7 @@ namespace quda
      @param[in] input_path Host-array holding all path contributions for the gauge action
      @param[in] length Host array holding the length of all paths
      @param[in] path_coeff Coefficient of each path
-     @param[in] num_paths Numer of paths
+     @param[in] num_paths Number of paths
      @param[in] max_length Maximum length of each path
    */
   void gaugeForce(GaugeField &mom, const GaugeField &u, double coeff, std::vector<int **> &input_path,
@@ -25,7 +25,7 @@ namespace quda
      @param[in] input_path Host-array holding all path contributions
      @param[in] length Host array holding the length of all paths
      @param[in] path_coeff Coefficient of each path
-     @param[in] num_paths Numer of paths
+     @param[in] num_paths Number of paths
      @param[in] max_length Maximum length of each path
    */
   void gaugePath(GaugeField &out, const GaugeField &u, double coeff, std::vector<int **> &input_path,
@@ -39,11 +39,45 @@ namespace quda
      @param[in] factor Multiplicative factor for each loop (i.e., volume normalization, etc)
      @param[in] length Host array holding the length of all paths
      @param[in] path_coeff Coefficient of each path
-     @param[in] num_paths Numer of paths
+     @param[in] num_paths Number of paths
      @param[in] path_max_length Maximum length of each path
    */
   void gaugeLoopTrace(const GaugeField &u, std::vector<Complex> &loop_traces, double factor,
                       std::vector<int **> &input_path, std::vector<int> &length, std::vector<double> &path_coeff_h,
                       int num_paths, int path_max_length);
 
+  /**
+     @brief Compute the product of gauge-links along the given paths
+     @param[out] out Array of scalar gauge field where the result is added to
+     @param[in] u Gauge field (extended when running on multiple GPUs)
+     @param[in] input_path Host-array holding all path contributions
+     @param[in] length Host array holding the length of all paths
+     @param[in] path_coeff Coefficient of each path
+     @param[in] num_paths Number of paths
+     @param[in] max_length Maximum length of each path
+   */
+  void gaugePaths(std::vector<GaugeField*> &out, const GaugeField &u, std::vector<int **> &input_path,
+		  std::vector<int> &length, int num_paths, int max_length);
+
+  /**
+     @brief Compute the product of gauge-links along the given paths inserting a gauge field at every step
+     @param[out] out Array of scalar gauge field where the result is added to
+     @param[in] u Gauge field (extended when running on multiple GPUs)
+     @param[in] ins Gauge field (extended when running on multiple GPUs)
+     @param[in] input_path Host-array holding all path contributions
+     @param[in] length Host array holding the length of all paths
+     @param[in] path_coeff Coefficient of each path
+     @param[in] num_paths Number of paths
+     @param[in] max_length Maximum length of each path
+   */
+  void gaugePathsWIns(std::vector<GaugeField*> &out, std::vector<GaugeField*> &out_wins, const GaugeField &u, const GaugeField &ins, bool left,
+		      std::vector<int **> &input_path, std::vector<int> &length, int num_paths, int max_length);
+
+  /**
+     @brief Project group to algebra
+     @param[out] mom Momentum field
+     @param[in] u Gauge field (extended when running on multiple GPUs)
+     @param[in] anti Whether making it an antihermitian matrix or not (default: true)
+   */
+  void gaugeToMom(GaugeField &mom, const GaugeField &u, bool anti=true);
 } // namespace quda
diff --git a/include/kernels/gauge_paths.cuh b/include/kernels/gauge_paths.cuh
new file mode 100644
index 0000000..31a8a4a
--- /dev/null
+++ b/include/kernels/gauge_paths.cuh
@@ -0,0 +1,81 @@
+#pragma once
+
+#include <gauge_field_order.h>
+#include <quda_matrix.h>
+#include <index_helper.cuh>
+#include <kernel.h>
+#include <thread_array.h>
+#include <array.h>
+#include <reduce_helper.h>
+#include <reduction_kernel.h>
+#include <gauge_path_helper.cuh>
+
+namespace quda {
+
+  template <typename store_t, int nColor_, QudaReconstructType recon_>
+  struct GaugePathsArg : kernel_param<> {
+    using real = typename mapper<store_t>::type;
+    static constexpr int nColor = nColor_;
+    static constexpr QudaReconstructType recon = recon_;
+    using Link = Matrix<complex<real>, nColor>;
+    static_assert(nColor == 3, "Only nColor=3 enabled at this time");
+    using Gauge = typename gauge_mapper<real,recon>::type;
+
+    const Gauge u;
+    Gauge *out;
+    const paths<1> p;
+
+    static constexpr int nParity = 2; // always true for gauge fields
+    int X[4]; // the regular volume parameters
+    int E[4]; // the extended volume parameters
+    int border[4]; // radius of border
+
+    GaugePathsArg(const GaugeField &u, Gauge *out_h, const paths<1> &p) :
+      kernel_param(dim3(u.VolumeCB(), 2, p.num_paths)),
+      u(u),
+      p(p)
+    {
+      size_t bytes = p.num_paths*sizeof(Gauge);
+      out = static_cast<Gauge*>(pool_device_malloc(bytes));
+      qudaMemcpy(out, out_h, bytes, qudaMemcpyHostToDevice);
+
+      for (int dir = 0; dir < 4; dir++) {
+        border[dir] = u.R()[dir];
+      	E[dir] = u.X()[dir];
+      	X[dir] = u.X()[dir] - border[dir]*2;
+      }
+    }
+    
+    void free() {
+      pool_device_free(out);
+    }
+  };
+
+  template <typename Arg> struct GaugePathsK
+  {
+    const Arg &arg;
+    constexpr GaugePathsK(const Arg &arg) : arg(arg) {}
+    static constexpr const char *filename() { return KERNEL_FILE; }
+
+    __device__ __host__ void operator()(int x_cb, int parity, int path_id)
+    {
+      using Link = typename Arg::Link;
+      using real = typename Arg::real;
+
+      int x[4] = {0, 0, 0, 0};
+      getCoords(x, x_cb, arg.X, parity);
+      for (int dr=0; dr<4; ++dr) x[dr] += arg.border[dr]; // extended grid coordinates
+
+      thread_array<int, 4> dx{0};
+
+      const int* path = arg.p.input_path[0] + path_id * arg.p.max_length;
+
+      // compute the path
+      Link link_prod = computeGaugePath(arg, x, parity, path, arg.p.length[path_id], dx);
+
+      // storing path
+      arg.out[path_id](0, x_cb, parity) = link_prod;
+    }
+  };
+
+}
diff --git a/include/kernels/gauge_paths_wins.cuh b/include/kernels/gauge_paths_wins.cuh
new file mode 100644
index 0000000..f2533f8
--- /dev/null
+++ b/include/kernels/gauge_paths_wins.cuh
@@ -0,0 +1,89 @@
+#pragma once
+
+#include <gauge_field_order.h>
+#include <quda_matrix.h>
+#include <index_helper.cuh>
+#include <kernel.h>
+#include <thread_array.h>
+#include <array.h>
+#include <reduce_helper.h>
+#include <reduction_kernel.h>
+#include <gauge_path_helper.cuh>
+
+namespace quda {
+
+  template <typename store_t, int nColor_, QudaReconstructType recon_, bool left_>
+  struct GaugePathsWInsArg : kernel_param<> {
+    using real = typename mapper<store_t>::type;
+    static constexpr bool left = left_;
+    static constexpr int nColor = nColor_;
+    static constexpr QudaReconstructType recon = recon_;
+    using Link = Matrix<complex<real>, nColor>;
+    static_assert(nColor == 3, "Only nColor=3 enabled at this time");
+    using Gauge = typename gauge_mapper<real,recon>::type;
+    using Mom = typename gauge_mapper<real,QUDA_RECONSTRUCT_10>::type;
+
+    const Gauge u;
+    const Mom ins;
+    Gauge *out;
+    Gauge *out_wins;
+    const paths<1> p;
+
+    static constexpr int nParity = 2; // always true for gauge fields
+    int X[4]; // the regular volume parameters
+    int E[4]; // the extended volume parameters
+    int border[4]; // radius of border
+
+    GaugePathsWInsArg(const GaugeField &u, const GaugeField &ins, Gauge *out_h, Gauge *out_wins_h, const paths<1> &p) :
+      kernel_param(dim3(u.VolumeCB(), 2, p.num_paths)),
+      u(u),
+      ins(ins),
+      p(p)
+    {
+      size_t bytes = p.num_paths*sizeof(Gauge);
+      out = static_cast<Gauge*>(pool_device_malloc(2*bytes));
+      out_wins = out+p.num_paths;
+      qudaMemcpy(out, out_h, bytes, qudaMemcpyHostToDevice);
+      qudaMemcpy(out_wins, out_wins_h, bytes, qudaMemcpyHostToDevice);
+
+      for (int dir = 0; dir < 4; dir++) {
+        border[dir] = u.R()[dir];
+      	E[dir] = u.X()[dir];
+      	X[dir] = u.X()[dir] - border[dir]*2;
+      }
+    }
+    
+    void free() {
+      pool_device_free(out);
+    }
+  };
+
+  template <typename Arg> struct GaugePathsWInsK
+  {
+    const Arg &arg;
+    constexpr GaugePathsWInsK(const Arg &arg) : arg(arg) {}
+    static constexpr const char *filename() { return KERNEL_FILE; }
+
+    __device__ __host__ void operator()(int x_cb, int parity, int path_id)
+    {
+      using Link = typename Arg::Link;
+      using real = typename Arg::real;
+
+      int x[4] = {0, 0, 0, 0};
+      getCoords(x, x_cb, arg.X, parity);
+      for (int dr=0; dr<4; ++dr) x[dr] += arg.border[dr]; // extended grid coordinates
+
+      thread_array<int, 4> dx{0};
+
+      const int* path = arg.p.input_path[0] + path_id * arg.p.max_length;
+
+      // compute the path
+      auto link_prod = computeGaugePathWIns(arg, x, parity, path, arg.p.length[path_id], dx);
+
+      // storing path
+      arg.out[path_id](0, x_cb, parity) = link_prod.A;
+      arg.out_wins[path_id](0, x_cb, parity) = link_prod.B;
+    }
+  };
+
+}
diff --git a/include/kernels/gauge_to_mom.cuh b/include/kernels/gauge_to_mom.cuh
new file mode 100644
index 0000000..1ae9afb
--- /dev/null
+++ b/include/kernels/gauge_to_mom.cuh
@@ -0,0 +1,51 @@
+#pragma once
+
+#include <gauge_field_order.h>
+#include <quda_matrix.h>
+#include <index_helper.cuh>
+#include <kernel.h>
+
+namespace quda {
+
+  template <typename Float_, int nColor_, QudaReconstructType recon_u, bool anti_>
+  struct GaugeToMomArg : kernel_param<> {
+    using Float = Float_;
+    static constexpr int nColor = nColor_;
+    static constexpr bool anti = anti_;
+    static_assert(nColor == 3, "Only nColor=3 enabled at this time");
+    typedef typename gauge_mapper<Float,recon_u>::type Gauge;
+    typedef typename gauge_mapper<Float,QUDA_RECONSTRUCT_10>::type Mom;
+
+    Mom out;
+    const Gauge in;
+
+    GaugeToMomArg(GaugeField &out, const GaugeField &in) :
+      kernel_param(dim3(in.VolumeCB(), 2, in.Geometry())),
+      out(out),
+      in(in)
+    {
+    }
+  };
+
+  template <typename Arg> struct GaugeToMomK
+  {
+    const Arg &arg;
+    constexpr GaugeToMomK(const Arg &arg) : arg(arg) {}
+    static constexpr const char *filename() { return KERNEL_FILE; }    
+
+    __device__ __host__ void operator()(int x_cb, int parity, int dir)
+    {
+      using real = typename Arg::Float;
+      typedef Matrix<complex<real>,Arg::nColor> Link;
+      
+      Link link = arg.in(dir, x_cb, parity);
+      if constexpr(Arg::anti) {
+	makeAntiHerm(link);
+      }	else {
+	makeIHerm(link);
+      }	
+      arg.out(dir, x_cb, parity) = link;
+    }
+  };
+  
+}
diff --git a/include/quda_matrix.h b/include/quda_matrix.h
index ce51093..db5cb31 100644
--- a/include/quda_matrix.h
+++ b/include/quda_matrix.h
@@ -739,17 +739,33 @@ namespace quda {
     __device__ __host__ inline void makeAntiHerm(Matrix<Complex,N> &m) {
     typedef typename Complex::value_type real;
     // first make the matrix anti-hermitian
-    Matrix<Complex,N> am = m - conj(m);
+    m = static_cast<real>(0.5) * (m - conj(m));
 
     // second make it traceless
     real imag_trace = 0.0;
 #pragma unroll
-    for (int i=0; i<N; i++) imag_trace += am(i,i).y;
+    for (int i=0; i<N; i++) imag_trace += m(i,i).y;
 #pragma unroll
     for (int i=0; i<N; i++) {
-      am(i,i).y -= imag_trace/N;
+      m(i,i).y -= imag_trace/N;
+    }
+  }
+
+  template<typename Complex,int N>
+    __device__ __host__ inline void makeIHerm(Matrix<Complex,N> &m) {
+    typedef typename Complex::value_type real;
+    // first make the matrix hermitian
+    Complex i_2(0.0, -0.5);
+    m = i_2 * (m + conj(m));
+
+    // second make it traceless
+    real imag_trace = 0.0;
+#pragma unroll
+    for (int i=0; i<N; i++) imag_trace += m(i,i).y;
+#pragma unroll
+    for (int i=0; i<N; i++) {
+      m(i,i).y -= imag_trace/N;
     }
-    m = static_cast<real>(0.5) * am;
   }
 
   template <typename Complex, int N> __device__ __host__ inline void makeHerm(Matrix<Complex, N> &m)
diff --git a/lib/gauge_paths.cu b/lib/gauge_paths.cu
new file mode 100644
index 0000000..d91c9d0
--- /dev/null
+++ b/lib/gauge_paths.cu
@@ -0,0 +1,76 @@
+#include <gauge_field.h>
+#include <gauge_path_quda.h>
+#include <instantiate.h>
+#include <tunable_nd.h>
+#include <kernels/gauge_paths.cuh>
+
+namespace quda {
+
+  template<typename Float, int nColor, QudaReconstructType recon>
+  class GaugePaths : public TunableKernel3D {
+    using real = typename mapper<Float>::type;
+    using Gauge = typename gauge_mapper<real,recon>::type;
+    const GaugeField &u;
+    std::vector<GaugeField*> &out0;
+    std::vector<Gauge> out;
+    const paths<1> &p;
+    unsigned int minThreads() const { return u.VolumeCB(); }
+
+  public:
+    GaugePaths(const GaugeField &u, std::vector<GaugeField*> &out, const paths<1>& p) :
+      TunableKernel3D(u, 2, p.num_paths),
+      u(u),
+      out0(out),
+      out(out.begin(),out.end()),
+      p(p)
+    {
+      if (p.num_paths != static_cast<int>(out.size()))
+	errorQuda("Out vector size %lu != number of paths %d", out.size(), p.num_paths);
+      
+      strcat(aux, "num_paths=");
+      char loop_str[4];
+      u32toa(loop_str, p.num_paths);
+      strcat(aux, loop_str);
+
+      apply(device::get_default_stream());
+    }
+
+    void apply(const qudaStream_t &stream)
+    {
+      TuneParam tp = tuneLaunch(*this, getTuning(), getVerbosity());
+      GaugePathsArg<Float, nColor, recon> arg(u, out.data(), p);
+      launch<GaugePathsK>(tp, stream, arg);
+      arg.free();
+    }
+
+    long long flops() const
+    {
+      auto Nc = u.Ncolor();
+      auto mat_mul_flops = 8ll * Nc * Nc * Nc - 2 * Nc * Nc;
+      // matrix multiplies + rescale
+      return (p.count * mat_mul_flops + p.num_paths * (Nc * Nc)) * u.Volume();
+    }
+
+    long long bytes() const {
+      // links * one LatticeColorMatrix worth of data
+      return p.count * u.Bytes() / 4;
+    }
+  };
+
+  void gaugePaths(std::vector<GaugeField*> &out, const GaugeField &u, std::vector<int **> &input_path,
+		  std::vector<int> &length, int num_paths, int max_length)
+  {
+    if (static_cast<int>(out.size()) != num_paths)
+      errorQuda("Output gauge vector is of size %lu, expected %d", out.size(), num_paths);
+    for (int i = 0; i < num_paths; i++) {
+      checkPrecision(*out[i], u);
+      checkLocation(*out[i], u);
+      checkReconstruct(*out[i], u);
+    }
+    std::vector<double> foo_coeff;
+    paths<1> p(input_path, length, foo_coeff, num_paths, max_length);
+    instantiate<GaugePaths, ReconstructNo12>(u, out, p);
+    p.free();
+  }
+
+} // namespace quda
diff --git a/lib/gauge_paths_wins.cu b/lib/gauge_paths_wins.cu
new file mode 100644
index 0000000..2481739
--- /dev/null
+++ b/lib/gauge_paths_wins.cu
@@ -0,0 +1,104 @@
+#include <gauge_field.h>
+#include <gauge_path_quda.h>
+#include <instantiate.h>
+#include <tunable_nd.h>
+#include <kernels/gauge_paths_wins.cuh>
+
+namespace quda {
+
+  template<typename Float, int nColor, QudaReconstructType recon>
+  class GaugePathsWIns : public TunableKernel3D {
+    using real = typename mapper<Float>::type;
+    using Gauge = typename gauge_mapper<real,recon>::type;
+    const GaugeField &u;
+    const GaugeField &ins;
+    std::vector<GaugeField*> &out0;
+    std::vector<GaugeField*> &out0_wins;
+    std::vector<Gauge> out;
+    std::vector<Gauge> out_wins;
+    const paths<1> &p;
+    bool left;
+    unsigned int minThreads() const { return u.VolumeCB(); }
+
+  public:
+    GaugePathsWIns(const GaugeField &u, std::vector<GaugeField*> &out, std::vector<GaugeField*> &out_wins, const GaugeField &ins, const paths<1>& p, bool left) :
+      TunableKernel3D(u, 2, p.num_paths),
+      u(u),
+      ins(ins),
+      out0(out),
+      out0_wins(out_wins),
+      out(out.begin(),out.end()),
+      out_wins(out_wins.begin(),out_wins.end()),
+      p(p),
+      left(left)
+    {
+      if (p.num_paths != static_cast<int>(out.size()))
+	errorQuda("Out vector size %lu != number of paths %d", out.size(), p.num_paths);
+      
+      strcat(aux, "num_paths=");
+      char loop_str[4];
+      u32toa(loop_str, p.num_paths);
+      strcat(aux, loop_str);
+
+      if(left)
+	strcat(aux, "left");
+      
+      apply(device::get_default_stream());
+    }
+
+    void apply(const qudaStream_t &stream)
+    {
+      TuneParam tp = tuneLaunch(*this, getTuning(), getVerbosity());
+      if(left) {
+	GaugePathsWInsArg<Float, nColor, recon, true> arg(u, ins, out.data(), out_wins.data(), p);
+	launch<GaugePathsWInsK>(tp, stream, arg);
+	arg.free();
+      }
+      else {
+	GaugePathsWInsArg<Float, nColor, recon, false> arg(u, ins, out.data(), out_wins.data(), p);
+	launch<GaugePathsWInsK>(tp, stream, arg);
+	arg.free();
+      }
+    }
+
+    long long flops() const
+    {
+      auto Nc = u.Ncolor();
+      auto mat_mul_flops = 8ll * Nc * Nc * Nc - 2 * Nc * Nc;
+      // TODO: matrix multiplies + rescale
+      return (p.count * mat_mul_flops + p.num_paths * (Nc * Nc)) * u.Volume();
+    }
+
+    long long bytes() const {
+      // links * one LatticeColorMatrix worth of data
+      return p.count * u.Bytes() / 4;
+    }
+  };
+
+  void gaugePathsWIns(std::vector<GaugeField*> &out, std::vector<GaugeField*> &out_wins, const GaugeField &u, const GaugeField &ins, bool left,
+		      std::vector<int **> &input_path, std::vector<int> &length, int num_paths, int max_length)
+  {
+    if (static_cast<int>(out.size()) != num_paths)
+      errorQuda("Output gauge vector is of size %lu, expected %d", out.size(), num_paths);
+    if (static_cast<int>(out_wins.size()) != num_paths)
+      errorQuda("Output gauge vector with insertion is of size %lu, expected %d", out.size(), num_paths);
+    checkPrecision(ins, u);
+    checkLocation(ins, u);
+    if (ins.Reconstruct() != QUDA_RECONSTRUCT_10)
+      errorQuda("Reconstruction type %d not supported, expected RECONSTRUCT_10", ins.Reconstruct());
+    
+    for (int i = 0; i < num_paths; i++) {
+      checkPrecision(*out[i], u);
+      checkLocation(*out[i], u);
+      checkReconstruct(*out[i], u);
+      checkPrecision(*out_wins[i], u);
+      checkLocation(*out_wins[i], u);
+      checkReconstruct(*out_wins[i], u);
+    }
+    std::vector<double> foo_coeff;
+    paths<1> p(input_path, length, foo_coeff, num_paths, max_length);
+    instantiate<GaugePathsWIns, ReconstructNo12>(u, out, out_wins, ins, p, left);
+    p.free();
+  }
+
+} // namespace quda
diff --git a/lib/gauge_to_mom.cu b/lib/gauge_to_mom.cu
new file mode 100644
index 0000000..bfb91a7
--- /dev/null
+++ b/lib/gauge_to_mom.cu
@@ -0,0 +1,61 @@
+#include <tunable_nd.h>
+#include <instantiate.h>
+#include <gauge_field.h>
+#include <kernels/gauge_to_mom.cuh>
+
+namespace quda {
+
+  template <typename Float, int nColor, QudaReconstructType recon_u> class GaugeToMom : public TunableKernel3D
+  {
+    GaugeField &out;
+    const GaugeField &in;
+    bool anti;
+    unsigned int minThreads() const { return in.VolumeCB(); }
+
+  public:
+    GaugeToMom(const GaugeField &in, GaugeField &out, bool anti) :
+      TunableKernel3D(in, 2, in.Geometry()),
+      out(out),
+      in(in),
+      anti(anti)
+    {
+      if(anti)
+	strcat(aux, ",anti=true");
+      else
+	strcat(aux, ",anti=false");
+      apply(device::get_default_stream());
+    }
+
+    void apply(const qudaStream_t &stream)
+    {
+      TuneParam tp = tuneLaunch(*this, getTuning(), getVerbosity());
+      if(anti)
+	launch<GaugeToMomK>(tp, stream, GaugeToMomArg<Float, nColor, recon_u, true>(out, in));
+      else
+	launch<GaugeToMomK>(tp, stream, GaugeToMomArg<Float, nColor, recon_u, false>(out, in));
+    }
+
+    void preTune() { }
+    void postTune() { }
+
+    long long flops() const { return in.Volume() * 4; }
+    long long bytes() const { return in.Bytes(); }
+  };
+
+  void gaugeToMom(GaugeField& out, const GaugeField& in, bool anti)
+  {
+    checkPrecision(in, out);
+    checkLocation(in, out);
+
+    if (out.Reconstruct() != QUDA_RECONSTRUCT_10)
+      errorQuda("Reconstruction type %d not supported", out.Reconstruct());
+
+    if (out.Geometry() != in.Geometry()) {
+      errorQuda("Field geometries %d %d do not match", out.Geometry(), in.Geometry());
+    }
+
+    // gauge field must be passed as first argument so we peel off its reconstruct type
+    instantiate<GaugeToMom>(in, out, anti);
+  }
+
+} // namespace quda
